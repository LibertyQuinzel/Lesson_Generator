"""
Test file for {{ test_target_name }}

This test file provides comprehensive coverage for {{ test_target_description | docstring }}.
When `is_template` is true this file is intentionally a student-facing template:
- It contains clear TODO instructions and a small failing placeholder so students can run tests and see what to implement.
- The given/when/then skeletons show where to place setup, action and assertions.
"""

import pytest

{% for import_stmt in test_imports %}
{{ import_stmt }}
{% endfor %}
from {{ module_path }} import {{ class_name }}


{% if is_template %}
"""
STUDENT TASK

This file is a template for students. Replace the TODO sections below with real tests that assert the
correct behaviour of the code in `{{ module_path }}/assignment_{{ tests_variant or 'a' }}.py`.

Guidance:
- Use the GIVEN / WHEN / THEN sections to structure each test.
- Keep tests small and focused: one assertion per behavioural expectation is fine.
- Provide at least four focused tests: one happy-path, one edge-case, one error/validation test,
  and one additional behavioural/contract test. Run pytest to see failing placeholders and iterate until all tests pass.
"""


def test_todo_template_{{ class_name|lower }}():
    """TODO: Write tests for {{ class_name }}.

    Example skeleton:

    # GIVEN
        # prepare inputs / fixtures
    # WHEN
        # call method under test
    # THEN
        # assert expected outcomes
    """
    pytest.fail("TEST TEMPLATE: implement tests for {{ class_name }} in this file -- replace this failure with real assertions")


# Helpful example (students can use this as a model)
def test_example_happy_path():
    # GIVEN
    obj = {{ class_name }}()
    # WHEN / THEN - example assertion showing how to call methods
    assert hasattr(obj, "demo") or True

{% if test_instructions %}
"""
Additional instructions:
{{ test_instructions }}
"""
{% endif %}

{% if test_methods %}
{% for t in test_methods %}
def test_{{ t.name }}():
    """{{ t.description | default('Test skeleton') }}"""
    # GIVEN
{{ (t.given_section | default('# TODO: setup', True)) | indent(4, True) }}
    # WHEN
{{ (t.when_section | default('# TODO: exercise', True)) | indent(4, True) }}
    # THEN
{{ (t.then_section | default('assert False, "TODO: add assertions"', True)) | indent(4, True) }}

{% endfor %}
{% endif %}

{% else %}

class Test{{ class_name }}:
    """
    Comprehensive test suite for {{ class_name }}.
    
    These tests cover:
    {% for coverage_area in test_coverage_areas %}
    - {{ coverage_area | docstring }}
    {% endfor %}
    """
    
    {% if fixtures %}
    {% for fixture in fixtures %}
    @pytest.fixture
    def {{ fixture.name }}(self):
        """{{ fixture.description }}"""
        {{ fixture.setup_code }}
    
    {% endfor %}
    {% endif %}
    
    {# Ensure at least 4 test methods are present by padding with placeholders if necessary #}
    {% set ns = namespace(tests=(test_methods or [])) %}
    {% for i in range((4 - (ns.tests|length)) if (ns.tests|length) < 4 else 0) %}
    {% set _ = ns.tests.append({
        'name': 'auto_placeholder_' ~ (ns.tests|length + 1),
        'description': 'Auto-generated placeholder test',
        'given_section': 'obj = ' ~ class_name ~ '()',
        'when_section': "# TODO: call method under test",
        'then_section': 'assert False, "TODO: implement test"',
    }) %}
    {% endfor %}

    {% for test_method in ns.tests %}
    def test_{{ test_method.name }}(self{% if test_method.fixtures %}, {{ test_method.fixtures|join(', ') }}{% endif %}):
{{ '        ' }}"""
{{ (test_method.description | docstring) | indent(8) }}
{{ '        ' }}
{{ '        ' }}Tests: {{ test_method.tests | docstring }}
{{ '        ' }}"""
    # GIVEN
{{ (test_method.given_section | default('', True)) | indent(8, True) }}
        
    # WHEN  
{{ (test_method.when_section | default('', True)) | indent(8, True) }}
        
    # THEN
{{ (test_method.then_section | default('', True)) | indent(8, True) }}
    
    {% endfor %}
    
    {% if parametrized_tests %}
    {% for param_test in parametrized_tests %}
    @pytest.mark.parametrize("{{ param_test.parameters }}", {{ param_test.test_data }})
    def test_{{ param_test.name }}(self, {{ param_test.parameters }}):
{{ '        ' }}"""
{{ (param_test.description | docstring) | indent(8) }}
{{ '        ' }}"""
    # GIVEN
{{ (param_test.given_section | default('', True)) | indent(8, True) }}
        
    # WHEN
{{ (param_test.when_section | default('', True)) | indent(8, True) }}
        
    # THEN  
{{ (param_test.then_section | default('', True)) | indent(8, True) }}
    
    {% endfor %}
    {% endif %}
    
    {% if error_tests %}
    {% for error_test in error_tests %}
    def test_{{ error_test.name }}_raises_{{ error_test.exception_name|lower }}(self):
{{ '        ' }}"""
{{ (error_test.description | docstring) | indent(8) }}
{{ '        ' }}"""
    # GIVEN
{{ (error_test.given_section | default('', True)) | indent(8, True) }}
        
        # WHEN/THEN
        with pytest.raises({{ error_test.exception_name }}){% if error_test.error_message %} as exc_info{% endif %}:
{{ (error_test.when_section | default('', True)) | indent(12, True) }}
        
        {% if error_test.error_message %}
        assert "{{ error_test.error_message }}" in str(exc_info.value)
        {% endif %}
    
    {% endfor %}
    {% endif %}


{% if integration_tests %}
class TestIntegration{{ class_name }}:
    """
    Integration tests for {{ class_name }} with external dependencies.
    """
    
    {% for integration_test in integration_tests %}
    def test_{{ integration_test.name }}(self):
{{ '        ' }}"""
{{ (integration_test.description | docstring) | indent(8) }}
{{ '        ' }}"""
{{ integration_test.implementation | indent(8, True) }}
    
    {% endfor %}
{% endif %}


{% if performance_tests %}
@pytest.mark.performance
class TestPerformance{{ class_name }}:
    """
    Performance tests for {{ class_name }}.
    Run with: pytest -m performance
    """
    
    {% for perf_test in performance_tests %}
    def test_{{ perf_test.name }}_performance(self):
{{ '        ' }}"""
{{ (perf_test.description | docstring) | indent(8) }}
{{ '        ' }}"""
        import time
        
        start_time = time.time()
{{ perf_test.implementation | indent(8, True) }}
        execution_time = time.time() - start_time
        
        assert execution_time < {{ perf_test.max_time }}, f"Execution took {execution_time:.2f}s, expected < {{ perf_test.max_time }}s"
    
    {% endfor %}
{% endif %}


# Additional test utilities
{% if test_utilities %}
{% for utility in test_utilities %}
def {{ utility.name }}({{ utility.parameters }}):
    """{{ utility.description }}"""
    {{ utility.implementation }}

{% endfor %}
{% endif %}


if __name__ == "__main__":
    # Run tests when file is executed directly
    pytest.main([__file__, "-v", "--tb=short"])
"""
Test file for {{ test_target_name }}

This test file provides comprehensive coverage for {{ test_target_description | docstring }}.
When `is_template` is true this file is intentionally a student-facing template:
- It contains clear TODO instructions and a small failing placeholder so students can run tests and see what to implement.
- The given/when/then skeletons show where to place setup, action and assertions.
"""

import pytest

{% for import_stmt in test_imports %}
{{ import_stmt }}
{% endfor %}
from {{ module_path }} import {{ class_name }}


{% if is_template %}
"""
STUDENT TASK

This file is a template for students. Replace the TODO sections below with real tests that assert the
correct behaviour of the code in `{{ module_path }}/assignment_{{ tests_variant or 'a' }}.py`.

Guidance:
- Use the GIVEN / WHEN / THEN sections to structure each test.
- Keep tests small and focused: one assertion per behavioural expectation is fine.
- Provide at least four focused tests: one happy-path, one edge-case, one error/validation test,
  and one additional behavioural/contract test. Run pytest to see failing placeholders and iterate until all tests pass.
"""


def test_todo_template_{{ class_name|lower }}():
    """TODO: Write tests for {{ class_name }}.

    Example skeleton:

    # GIVEN
        # prepare inputs / fixtures
    # WHEN
        # call method under test
    # THEN
        # assert expected outcomes
    """
    pytest.fail("TEST TEMPLATE: implement tests for {{ class_name }} in this file -- replace this failure with real assertions")


# Helpful example (students can use this as a model)
def test_example_happy_path():
    # GIVEN
    obj = {{ class_name }}()
    # WHEN / THEN - example assertion showing how to call methods
    assert hasattr(obj, "demo") or True

{% if test_instructions %}
"""
Additional instructions:
{{ test_instructions }}
"""
{% endif %}

{% if test_methods %}
{% for t in test_methods %}
def test_{{ t.name }}():
    """{{ t.description | default('Test skeleton') }}"""
    # GIVEN
{{ (t.given_section | default('# TODO: setup', True)) | indent(4, True) }}
    # WHEN
{{ (t.when_section | default('# TODO: exercise', True)) | indent(4, True) }}
    # THEN
{{ (t.then_section | default('assert False, "TODO: add assertions"', True)) | indent(4, True) }}

{% endfor %}
{% endif %}

{% else %}

class Test{{ class_name }}:
    """
    Comprehensive test suite for {{ class_name }}.
    
    These tests cover:
    {% for coverage_area in test_coverage_areas %}
    - {{ coverage_area | docstring }}
    {% endfor %}
    """
    
    {% if fixtures %}
    {% for fixture in fixtures %}
    @pytest.fixture
    def {{ fixture.name }}(self):
        """{{ fixture.description }}"""
        {{ fixture.setup_code }}
    
    {% endfor %}
    {% endif %}
    
    {# Ensure at least 4 test methods are present by padding with placeholders if necessary #}
    {% set ns = namespace(tests=(test_methods or [])) %}
    {% for i in range((4 - (ns.tests|length)) if (ns.tests|length) < 4 else 0) %}
    {% set _ = ns.tests.append({
        'name': 'auto_placeholder_' ~ (ns.tests|length + 1),
        'description': 'Auto-generated placeholder test',
        'given_section': 'obj = ' ~ class_name ~ '()',
        'when_section': "# TODO: call method under test",
        'then_section': 'assert False, "TODO: implement test"',
    }) %}
    {% endfor %}

    {% for test_method in ns.tests %}
    def test_{{ test_method.name }}(self{% if test_method.fixtures %}, {{ test_method.fixtures|join(', ') }}{% endif %}):
{{ '        ' }}"""
{{ (test_method.description | docstring) | indent(8) }}
{{ '        ' }}
{{ '        ' }}Tests: {{ test_method.tests | docstring }}
{{ '        ' }}"""
    # GIVEN
{{ (test_method.given_section | default('', True)) | indent(8, True) }}
        
    # WHEN  
{{ (test_method.when_section | default('', True)) | indent(8, True) }}
        
    # THEN
{{ (test_method.then_section | default('', True)) | indent(8, True) }}
    
    {% endfor %}
    
    {% if parametrized_tests %}
    {% for param_test in parametrized_tests %}
    @pytest.mark.parametrize("{{ param_test.parameters }}", {{ param_test.test_data }})
    def test_{{ param_test.name }}(self, {{ param_test.parameters }}):
{{ '        ' }}"""
{{ (param_test.description | docstring) | indent(8) }}
{{ '        ' }}"""
    # GIVEN
{{ (param_test.given_section | default('', True)) | indent(8, True) }}
        
    # WHEN
{{ (param_test.when_section | default('', True)) | indent(8, True) }}
        
    # THEN  
{{ (param_test.then_section | default('', True)) | indent(8, True) }}
    
    {% endfor %}
    {% endif %}
    
    {% if error_tests %}
    {% for error_test in error_tests %}
    def test_{{ error_test.name }}_raises_{{ error_test.exception_name|lower }}(self):
{{ '        ' }}"""
{{ (error_test.description | docstring) | indent(8) }}
{{ '        ' }}"""
    # GIVEN
{{ (error_test.given_section | default('', True)) | indent(8, True) }}
        
        # WHEN/THEN
        with pytest.raises({{ error_test.exception_name }}){% if error_test.error_message %} as exc_info{% endif %}:
{{ (error_test.when_section | default('', True)) | indent(12, True) }}
        
        {% if error_test.error_message %}
        assert "{{ error_test.error_message }}" in str(exc_info.value)
        {% endif %}
    
    {% endfor %}
    {% endif %}


{% if integration_tests %}
class TestIntegration{{ class_name }}:
    """
    Integration tests for {{ class_name }} with external dependencies.
    """
    
    {% for integration_test in integration_tests %}
    def test_{{ integration_test.name }}(self):
{{ '        ' }}"""
{{ (integration_test.description | docstring) | indent(8) }}
{{ '        ' }}"""
{{ integration_test.implementation | indent(8, True) }}
    
    {% endfor %}
{% endif %}


{% if performance_tests %}
@pytest.mark.performance
class TestPerformance{{ class_name }}:
    """
    Performance tests for {{ class_name }}.
    Run with: pytest -m performance
    """
    
    {% for perf_test in performance_tests %}
    def test_{{ perf_test.name }}_performance(self):
{{ '        ' }}"""
{{ (perf_test.description | docstring) | indent(8) }}
{{ '        ' }}"""
        import time
        
        start_time = time.time()
{{ perf_test.implementation | indent(8, True) }}
        execution_time = time.time() - start_time
        
        assert execution_time < {{ perf_test.max_time }}, f"Execution took {execution_time:.2f}s, expected < {{ perf_test.max_time }}s"
    
    {% endfor %}
{% endif %}

{% endif %}


# Additional test utilities
{% if test_utilities %}
{% for utility in test_utilities %}
def {{ utility.name }}({{ utility.parameters }}):
    """{{ utility.description }}"""
    {{ utility.implementation }}

{% endfor %}
{% endif %}


if __name__ == "__main__":
    # Run tests when file is executed directly
    pytest.main([__file__, "-v", "--tb=short"])
